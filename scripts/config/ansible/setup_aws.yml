---
- hosts: all
  strategy: free
  vars:
    data_disks:
      - /dev/nvme1n1
    mnt_prefix: /mnt/data
    tmpfs_path: /mnt/tmpfs
    awsdir: ~/.aws
    workdir: ~/raysort
    pythondir: ~/miniconda3/envs/raysort/bin
    hosts_path: /etc/hosts
    hadoop_config_path: /opt/hadoop/etc/hadoop
    spark_config_path: /opt/spark/conf
  tasks:
    - name: Create a filesystem on each of the data disks
      become: true
      community.general.filesystem:
        fstype: ext4
        dev: "{{item}}"
      loop: "{{data_disks}}"

    - name: Create data disk mount points
      become: true
      file:
        path: "{{mnt_prefix}}{{item}}"
        state: directory
      loop: "{{ range(data_disks|length)|list }}"

    - name: Mount the data disks
      become: true
      mount:
        path: "{{mnt_prefix}}{{idx}}"
        src: "{{item}}"
        fstype: ext4
        state: mounted
      when: mnt_prefix and data_disks
      loop: "{{data_disks}}"
      loop_control:
        index_var: idx

    - name: Create tmpfs mount point
      become: true
      file:
        path: "{{tmpfs_path}}"
        state: directory

    - name: Mount tmpfs
      become: true
      mount:
        path: "{{tmpfs_path}}"
        src: tmpfs
        fstype: tmpfs
        state: mounted

    - name: Set tmpfs permission
      become: true
      file:
        path: "{{tmpfs_path}}"
        state: directory
        mode: "777"

    - name: Clear temp directories
      become: true
      file:
        path: "{{mnt_prefix}}{{item}}/tmp"
        state: absent
        mode: "777"
      when: mnt_prefix and data_disks
      loop: "{{ range(data_disks|length)|list }}"

    - name: Make temp directories
      become: true
      file:
        path: "{{mnt_prefix}}{{item}}/tmp"
        state: directory
        mode: "777"
      when: mnt_prefix and data_disks
      loop: "{{ range(data_disks|length)|list }}"

    - name: Sync aws directory
      synchronize:
        src: "{{awsdir}}/"
        dest: "{{awsdir}}"
        delete: true

    - name: Sync workdir
      synchronize:
        src: "{{workdir}}/"
        dest: "{{workdir}}"
        delete: true
        rsync_opts:
          - --exclude=.git
          - --exclude=data

    - name: Install Python dependencies
      shell: "{{pythondir}}/pip install -Ur {{workdir}}/requirements/worker.txt"

    - name: Install project packages
      shell: |
        cd {{workdir}} && {{pythondir}}/pip install -e .
        cd {{workdir}}/raysort/sortlib && {{pythondir}}/python setup.py build_ext --inplace

    - name: Set soft and hard ulimit
      become: true
      community.general.pam_limits:
        domain: "*"
        limit_type: "{{item}}"
        limit_item: nofile
        value: 65535
      loop:
        - hard
        - soft

    - name: Check Hadoop files exist
      delegate_to: localhost
      stat:
        path: "{{hadoop_config_path}}"
      register: hadoop

    - name: Sync hosts file
      become: true
      copy:
        src: "{{hosts_path}}"
        dest: "{{hosts_path}}"
      when: hadoop

    - name: Copy Hadoop core-site.xml
      copy:
        src: "{{hadoop_config_path}}/core-site.xml"
        dest: "{{hadoop_config_path}}/core-site.xml"
      when: hadoop

    - name: Copy Hadoop yarn-site.xml
      copy:
        src: "{{hadoop_config_path}}/yarn-site.xml"
        dest: "{{hadoop_config_path}}/yarn-site.xml"
      when: hadoop

    - name: Start Node Exporter
      shell: >
        nohup
        {{workdir}}/raysort/bin/node_exporter/node_exporter
        --web.listen-address 0.0.0.0:8091 &
